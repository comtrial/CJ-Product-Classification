{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28897,"status":"ok","timestamp":1644535068989,"user":{"displayName":"최수산","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15495732425338237971"},"user_tz":-540},"id":"100TEGz7tERY","outputId":"b7ace5fc-7b31-4541-a8f0-928cd1d745cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers\n","  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n","\u001b[K     |████████████████████████████████| 3.5 MB 5.3 MB/s \n","\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n","  Downloading tokenizers-0.11.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 28.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.10.1)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 2.7 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 45.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 35.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.4 transformers-4.16.2\n"]}],"source":["!pip install transformers\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","import pandas as pd\n","import sklearn\n","import torch # 파이토치 패키지 임포트\n","import torch.nn as nn # 자주 사용하는 torch.nn패키지를 별칭 nn으로 명명\n","from torch.utils.data import DataLoader\n","import pandas as pd\n","from torch.utils.data import Dataset # Dataset 클래스 임포트\n","import transformers\n","from transformers import AdamW, get_linear_schedule_with_warmup"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DukGz_YlQoFj"},"outputs":[],"source":["train_data = pd.read_csv(\"/content/drive/MyDrive/colab_data/cj_data/data/final_dataset/N2C_train_v2_tokenized.csv\")\n","test_data = pd.read_csv(\"/content/drive/MyDrive/colab_data/cj_data/data/final_dataset/N2C_test_v2_tokenized.csv\")\n","\n","data_df = pd.concat([train_data, test_data])\n","\n","# make ctg code mapping table\n","ctg_dict = data_df[['middle_classification', 'main_ctg', 'midd_ctg']].drop_duplicates()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rm6RscoFLM65"},"outputs":[],"source":["val_data = train_data[:1024]\n","train_data = train_data[1024:]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1644535074527,"user":{"displayName":"최수산","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15495732425338237971"},"user_tz":-540},"id":"ui0xiBnvvG_3","outputId":"3162c32f-24a9-412a-de6c-127ff357cd3c"},"outputs":[{"data":{"text/plain":["165"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["test_data.midd_ctg.unique().shape[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HpNwsobu6sa"},"outputs":[],"source":["\n","# import torch # 파이토치 패키지 임포트\n","# import torch.nn as nn # 자주 사용하는 torch.nn패키지를 별칭 nn으로 명명\n","# from transformers import BertConfig, BertModel\n","# # 허깅페이스의 트랜스포머 패키지에서 BertConfig, BertModel 클래스 임포트\n","\n","# class CategoryClassifier(nn.Module):\n","#     \"\"\"상품정보를 받아서 대/중/소/세 카테고리를 예측하는 모델    \n","#     \"\"\"\n","#     def __init__(self, cfg):\n","#       super(CategoryClassifier, self).__init__()\n","\n","#       # 글로벌 설정 값 사용\n","#       self.cfg = cfg\n","#       # 버트모델의 설정값을 멤버 변수로 저장\n","#       self.bert_cfg = BertConfig( \n","#           cfg.vocab_size, # 사전 크기\n","#           hidden_size=cfg.hidden_size, # 히든 크기\n","#           num_hidden_layers=cfg.nlayers, # 레이어 층 수\n","#           num_attention_heads=cfg.nheads, # 어텐션 헤드의 수\n","#           intermediate_size=cfg.intermediate_size, # 인터미디어트 크기\n","#           hidden_dropout_prob=cfg.dropout, # 히든 드롭아웃 확률 값\n","#           attention_probs_dropout_prob=cfg.dropout, # 어텐션 드롭아웃 확률 값 \n","#           max_position_embeddings=cfg.seq_len, # 포지션 임베딩의 최대 길이\n","#           type_vocab_size=cfg.type_vocab_size, # 타입 사전 크기\n","#       )\n","#       # 텍스트 인코더로 버트모델 사용\n","#       self.text_encoder = BertModel(self.bert_cfg)\n","\n","#       def get_classifiier(target_size):\n","#         return nn.Sequential(\n","#           nn.Linear(cfg.text_encoder_size, cfg.hidden_size),\n","#                     nn.LayerNorm(cfg.hidden_size),\n","#                     nn.Dropout(cfg.dropout),\n","#                     nn.ReLU(),\n","#                     nn.Linear(cfg.hidden_size, target_size),\n","#         )\n","\n","#       # 대 카테고리 분류기\n","#       self.main_cls = get_classifiier(cfg.main_ctg)\n","#       # 중 카테고리 분류기\n","#       self.midd_cls = get_classifiier(cfg.midd_ctg)\n","\n","\n","\n","#     def forward(self, token_ids, token_mask, token_types, label=None):\n","#       \"\"\"        \n","#       매개변수\n","#       token_ids: 전처리된 상품명을 인덱스로 변환하여 token_ids를 만들었음\n","#       token_mask: 실제 token_ids의 개수만큼은 1, 나머지는 0으로 채움\n","#       token_types: ▁ 문자를 기준으로 서로 다른 타입의 토큰임을 타입 인덱스로 저장\n","#       img_feat: resnet50으로 인코딩된 이미지 피처\n","#       label: 정답 대/중/소/세 카테고리\n","#       \"\"\"\n","#       # 전처리된 상품명을 하나의 텍스트벡터(text_vec)로 변환\n","#       # 반환 튜플(시퀀스 아웃풋, 풀드(pooled) 아웃풋) 중 시퀀스 아웃풋만 사용\n","#       text_output = self.text_encoder(token_ids, token_mask, token_type_ids=token_types)[0]\n","      \n","#       # 시퀀스 중 첫 타임스탭의 hidden state만 사용. \n","#       text_vec = text_output[:, 0]\n","\n","\n","\n","\n","#       # 결합된 벡터로 대카테고리 확률분포 예측\n","#       main_pred = self.main_cls(text_vec)\n","#       # 결합된 벡터로 중카테고리 확률분포 예측\n","#       midd_pred = self.midd_cls(text_vec)\n","\n","\n","#       main_label, midd_label = label.split(1,1)\n","\n","#       loss_fuc = nn.CrossEntropyLoss(ignore_index= -1)\n","\n","#     #   loss_fuc.cuda()\n","\n","#       main_loss = loss_fuc(main_pred, main_label.view(-1))\n","#       # 중카테고리의 예측된 확률분포와 정답확률 분포의 차이를 손실로 반환\n","#       midd_loss = loss_fuc(midd_pred, midd_label.view(-1))\n","\n","#       # loss = (1*main_loss + 1.7*midd_loss) / 2\n","\n","#       # 중뷴류 정확도를 높이기 위하여\n","#       loss = midd_loss\n","\n","#       return loss, [main_pred, midd_pred]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GGEkm4JZhrIR"},"outputs":[],"source":["## Make DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gGc1b6MrztXJ"},"outputs":[],"source":["# import pandas as pd\n","# from torch.utils.data import Dataset # Dataset 클래스 임포트\n","# import re # 정규식표현식 모듈 임포트 \n","\n","# class CategoryDataSet(Dataset):\n","#     def __init__(self, df_data, token2id, tokens_max_len=64, type_vocab_size=30):\n","#       \"\"\"        \n","#       매개변수\n","#       df_data: 상품타이틀, 카테고리 등의 정보를 가지는 데이터프레임\n","#       token2id: token을 token_id로 변환하기 위한 맵핑 정보를 가진 딕셔너리\n","#       tokens_max_len: tokens의 최대 길이. 상품명의 tokens가 이 이상이면 잘라서 버림\n","#       type_vocab_size: 타입 사전의 크기\n","#       \"\"\"\n","#       self.tokens = df_data['tokens'].values # 전처리된 상품명    \n","#     #   self.input_embedding = df_data['name_embedding'].values\n","#       self.tokens_max_len = tokens_max_len\n","#       # self.labels = df_data[['bcateid', 'mcateid', 'scateid', 'dcateid']].values\n","#       self.token2id = token2id \n","#       self.p = re.compile('▁[^▁]+') # ▁기호를 기준으로 나누기 위한 컴파일된 정규식\n","#       self.type_vocab_size = type_vocab_size\n","#       self.labels = df_data[['main_ctg', 'midd_ctg']].values\n","\n","#       #custom\n","#       # self.sentence_model = sentence_model\n","\n","#     def __getitem__(self,idx):\n","\n","#       if idx >= len(self):\n","#             raise StopIteration\n","\n","#       # idx에 해당하는 상품명 가져오기. 상품명은 문자열로 저장돼 있음\n","#       tokens = self.tokens[idx]\n","#       if not isinstance(tokens, str):\n","#           tokens = ''\n","      \n","#       # 상품명을 ▁기호를 기준으로 분리하여 파이썬 리스트로 저장\n","#       # \"▁직소퍼즐 ▁1000 조각 ▁바다 거북 의 ▁여행 ▁pl 12 75\" =>\n","#       # [\"▁직소퍼즐\", \"▁1000 조각\", \"▁바다 거북 의\", \"▁여행\", \"▁pl 12 75\"]\n","#       tokens = self.p.findall(tokens)\n","      \n","#       # ▁ 기호 별 토큰타입 인덱스 부여\n","#       # [\"▁직소퍼즐\", \"▁1000 조각\", \"▁바다 거북 의\", \"▁여행\", \"▁pl 12 75\"] =>\n","#       # [     0     ,     1    1  ,    2     2  2 ,     3   ,   4  4   4 ]\n","#       token_types = [type_id for type_id, word in enumerate(tokens) for _ in word.split()]       \n","#       tokens = \" \".join(tokens) # ▁기호로 분리되기 전의 원래의 tokens으로 되돌림\n","\n","#       # 토큰을 토큰에 대응되는 인덱스로 변환\n","#       # \"▁직소퍼즐 ▁1000 조각 ▁바다 거북 의 ▁여행 ▁pl 12 75\" =>\n","#       # [2291, 784, 2179, 3540, 17334, 30827, 1114, 282, 163, 444]\n","#       # \"▁직소퍼즐\" => 2291\n","#       # \"▁1000\" => 784\n","#       # \"조각\" => 2179\n","#       # ...\n","#       token_ids = [self.token2id[tok] if tok in self.token2id else 0 for tok in tokens.split()]\n","      \n","#       # token_ids의 길이가 max_len보다 길면 잘라서 버림\n","#       if len(token_ids) > self.tokens_max_len:\n","#           token_ids = token_ids[:self.tokens_max_len]      \n","#           token_types = token_types[:self.tokens_max_len]\n","      \n","#       # token_ids의 길이가 max_len보다 짧으면 짧은만큼 PAD값 0 값으로 채워넣음\n","#       # token_ids 중 값이 있는 곳은 1, 그 외는 0으로 채운 token_mask 생성\n","#       token_mask = [1] * len(token_ids)\n","#       token_pad = [0] * (self.tokens_max_len - len(token_ids))\n","#       token_ids += token_pad\n","#       token_mask += token_pad\n","#       token_types += token_pad # max_len 보다 짧은만큼 PAD 추가\n","\n","\n","\n","\n","\n","\n","#       # 넘파이(numpy)나 파이썬 자료형을 파이토치의 자료형으로 변환\n","#       token_ids = torch.LongTensor(token_ids)\n","#       token_mask = torch.LongTensor(token_mask)\n","#       token_types = torch.LongTensor(token_types)\n","      \n","#       # token_types의 타입 인덱스의 숫자 크기가 type_vocab_size 보다 작도록 바꿈\n","#       token_types[token_types >= self.type_vocab_size] = self.type_vocab_size-1 \n","\n","\n","#       # 대/중/소/세 라벨 준비\n","#       label = self.labels[idx]\n","#       label = torch.LongTensor(label)\n","#       # label = self.labels[idx]\n","#       # label = torch.LongTensor(label)\n","\n","#       # 크게 3가지 텍스트 입력, 이미지 입력, 라벨을 반환한다.\n","#       return token_ids, token_mask, token_types, label\n","#       # \n","      \n","#     def __len__(self):\n","#       # 가지고 있는 데이터셋의 길이를 반환한다.\n","#       return len(self.tokens) # 1314\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72U_byyHPuHq"},"outputs":[],"source":["\n","def calc_cate_acc(pred, label):\n","    \"\"\"\n","    대/중/소/세 카테고리별 정확도와 전체(overall) 정확도를 반환\n","    전체 정확도는 대회 평가 방법과 동일한 가중치로 계산\n","    \"\"\"\n","    main_pred, midd_pred = pred    \n","    _, main_idx = main_pred.max(1)\n","    _, midd_idx = midd_pred.max(1)\n","\n","    #(label[:, 0]>0) -> (label[:, 0]>=0) 후에 문제 생길 수도 잇ㅇㄹ거 같아\n","        \n","    main_acc = (main_idx == label[:, 0]).sum().item() / (label[:, 0]>=0).sum().item()\n","    midd_acc = (midd_idx == label[:, 1]).sum().item() / (label[:, 1]>=0).sum().item()\n","    \n","    o_acc = (main_acc + 1.7*midd_acc)/2\n","\n","    return o_acc, main_acc, midd_acc\n","\n","def save_checkpoint(state, model_path, model_filename, is_best=False):\n","    print('saving cust_model ...')\n","    if not os.path.exists(model_path):\n","        os.makedirs(model_path)\n","    torch.save(state, os.path.join(model_path, model_filename))\n","    if is_best:\n","        torch.save(state, os.path.join(model_path, 'best_' + model_filename))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OA6CXC1ICXKc"},"outputs":[],"source":["## Make main() as trainer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eIJGc8sXEve2"},"outputs":[],"source":["def train(train_loader, val_loader,model, optimizer, epoch, scheduler):\n","  \"\"\"    \n","    한 에폭 단위로 학습을 시킵니다.\n","\n","    매개변수\n","    train_loader: 학습 데이터셋에서 배치(미니배치) 불러옵니다.\n","    model: 학습될 파라미터를 가진 딥러닝 모델\n","    optimizer: 파라미터를 업데이트 시키는 역할\n","    scheduler: learning_rate를 감소시키는 역할\n","  \"\"\"\n","  model.train()\n","\n","  for step, (token_ids, token_mask, token_types, label) in enumerate(train_loader):\n","\n","    # to cuda\n","    # token_ids, token_mask, token_types, label = (token_ids.cuda(), token_mask.cuda(), token_types.cuda(), label.cuda())\n","\n","\n","    loss, pred = model(token_ids, token_mask, token_types, label)\n","\n","    optimizer.zero_grad() # 옵티마이저 내의 그래디언트 초기화\n","    loss.backward()\n","\n","    scheduler.step()    # 스케쥴러로 learning_rate 조절\n","    optimizer.step()    # 옵티마이저로 파라미터 업데이터\n","\n","    if step % CFG.print_freq == 0 or step ==(len(train_loader) - 1):\n","      o_acc, main_acc, midd_acc = calc_cate_acc(pred, label)\n","\n","      print(f'{step} step train acc     : {o_acc, main_acc, midd_acc}')\n","\n","      if step % 1000 == 0 or step ==(len(train_loader) - 1):\n","        validation(model, val_loader)\n","  return\n","\n","def validation(model, val_loader):\n","\n","  for step, (token_ids, token_mask, token_types, label) in enumerate(val_loader):\n","\n","    with torch.no_grad():\n","        loss, pred = model(token_ids, token_mask, token_types, label)\n","    \n","    o_acc, main_acc, midd_acc = calc_cate_acc(pred, label)\n","\n","\n","    print('='*100)\n","    print(f'{step} step val acc     : {o_acc, main_acc, midd_acc}')\n","    print('+'*100)\n","  return"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zYl6YHGTD7-T"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"HoccAeB4EtNj","outputId":"f2e5294d-1e93-4c9c-ff5b-4ee217318aea"},"outputs":[{"name":"stdout","output_type":"stream","text":["cpu\n","loading ... done\n","num_train_optimization_steps 35180\n","use WarmupLinearSchedule ...\n","initial learning rate:0.0\n","CategoryClassifier(\n","  (text_encoder): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n","      (position_embeddings): Embedding(64, 768)\n","      (token_type_embeddings): Embedding(30, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.2, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=256, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=256, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.2, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=256, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=256, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.2, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (main_cls): Sequential(\n","    (0): Linear(in_features=768, out_features=768, bias=True)\n","    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (2): Dropout(p=0.2, inplace=False)\n","    (3): ReLU()\n","    (4): Linear(in_features=768, out_features=11, bias=True)\n","  )\n","  (midd_cls): Sequential(\n","    (0): Linear(in_features=768, out_features=768, bias=True)\n","    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","    (2): Dropout(p=0.2, inplace=False)\n","    (3): ReLU()\n","    (4): Linear(in_features=768, out_features=165, bias=True)\n","  )\n",")\n","0\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"name":"stdout","output_type":"stream","text":["0 step train acc     : (0.665625, 0.109375, 0.71875)\n","====================================================================================================\n","0 step val acc     : (0.730078125, 0.072265625, 0.81640625)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","10 step train acc     : (0.6734375, 0.125, 0.71875)\n","20 step train acc     : (0.62109375, 0.046875, 0.703125)\n","30 step train acc     : (0.7671875, 0.046875, 0.875)\n","40 step train acc     : (0.70078125, 0.046875, 0.796875)\n","50 step train acc     : (0.7328125, 0.03125, 0.84375)\n","60 step train acc     : (0.74765625, 0.140625, 0.796875)\n","70 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","80 step train acc     : (0.771875, 0.109375, 0.84375)\n","90 step train acc     : (0.7640625, 0.09375, 0.84375)\n","100 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","110 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","120 step train acc     : (0.7328125, 0.03125, 0.84375)\n","130 step train acc     : (0.80625, 0.125, 0.875)\n","140 step train acc     : (0.61796875, 0.09375, 0.671875)\n","150 step train acc     : (0.6710937499999999, 0.09375, 0.734375)\n","160 step train acc     : (0.6875, 0.046875, 0.78125)\n","170 step train acc     : (0.7484375, 0.0625, 0.84375)\n","180 step train acc     : (0.6234375, 0.078125, 0.6875)\n","190 step train acc     : (0.7109375, 0.09375, 0.78125)\n","200 step train acc     : (0.75859375, 0.109375, 0.828125)\n","210 step train acc     : (0.70078125, 0.046875, 0.796875)\n","220 step train acc     : (0.74296875, 0.078125, 0.828125)\n","230 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","240 step train acc     : (0.64453125, 0.09375, 0.703125)\n","250 step train acc     : (0.6875, 0.046875, 0.78125)\n","260 step train acc     : (0.78515625, 0.109375, 0.859375)\n","270 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","280 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","290 step train acc     : (0.6953125, 0.0625, 0.78125)\n","300 step train acc     : (0.759375, 0.03125, 0.875)\n","310 step train acc     : (0.73515625, 0.0625, 0.828125)\n","320 step train acc     : (0.75078125, 0.09375, 0.828125)\n","330 step train acc     : (0.76640625, 0.125, 0.828125)\n","340 step train acc     : (0.77421875, 0.140625, 0.828125)\n","350 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","360 step train acc     : (0.71953125, 0.03125, 0.828125)\n","370 step train acc     : (0.7828125, 0.078125, 0.875)\n","380 step train acc     : (0.6265625, 0.03125, 0.71875)\n","390 step train acc     : (0.62890625, 0.0625, 0.703125)\n","400 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","410 step train acc     : (0.6953125, 0.0625, 0.78125)\n","420 step train acc     : (0.703125, 0.078125, 0.78125)\n","430 step train acc     : (0.7843749999999999, 0.1875, 0.8125)\n","440 step train acc     : (0.80625, 0.125, 0.875)\n","450 step train acc     : (0.71875, 0.109375, 0.78125)\n","460 step train acc     : (0.73515625, 0.0625, 0.828125)\n","470 step train acc     : (0.7265625, 0.125, 0.78125)\n","480 step train acc     : (0.7515625, 0.015625, 0.875)\n","490 step train acc     : (0.76640625, 0.125, 0.828125)\n","500 step train acc     : (0.65234375, 0.109375, 0.703125)\n","510 step train acc     : (0.75625, 0.078125, 0.84375)\n","520 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","530 step train acc     : (0.74296875, 0.078125, 0.828125)\n","540 step train acc     : (0.70859375, 0.0625, 0.796875)\n","550 step train acc     : (0.75390625, 0.046875, 0.859375)\n","560 step train acc     : (0.73046875, 0.0, 0.859375)\n","570 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","580 step train acc     : (0.76171875, 0.0625, 0.859375)\n","590 step train acc     : (0.73515625, 0.0625, 0.828125)\n","600 step train acc     : (0.7062499999999999, 0.03125, 0.8125)\n","610 step train acc     : (0.6554687499999999, 0.0625, 0.734375)\n","620 step train acc     : (0.7671875, 0.046875, 0.875)\n","630 step train acc     : (0.73984375, 0.125, 0.796875)\n","640 step train acc     : (0.68203125, 0.0625, 0.765625)\n","650 step train acc     : (0.74765625, 0.140625, 0.796875)\n","660 step train acc     : (0.75625, 0.078125, 0.84375)\n","670 step train acc     : (0.73203125, 0.109375, 0.796875)\n","680 step train acc     : (0.6875, 0.046875, 0.78125)\n","690 step train acc     : (0.825, 0.109375, 0.90625)\n","700 step train acc     : (0.70078125, 0.046875, 0.796875)\n","710 step train acc     : (0.771875, 0.109375, 0.84375)\n","720 step train acc     : (0.75625, 0.078125, 0.84375)\n","730 step train acc     : (0.7953125, 0.15625, 0.84375)\n","740 step train acc     : (0.78203125, 0.15625, 0.828125)\n","750 step train acc     : (0.71640625, 0.078125, 0.796875)\n","760 step train acc     : (0.77734375, 0.09375, 0.859375)\n","770 step train acc     : (0.72421875, 0.09375, 0.796875)\n","780 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","790 step train acc     : (0.6953125, 0.0625, 0.78125)\n","800 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","810 step train acc     : (0.8351562499999999, 0.15625, 0.890625)\n","820 step train acc     : (0.73515625, 0.0625, 0.828125)\n","830 step train acc     : (0.77734375, 0.09375, 0.859375)\n","840 step train acc     : (0.75078125, 0.09375, 0.828125)\n","850 step train acc     : (0.740625, 0.046875, 0.84375)\n","860 step train acc     : (0.6476562499999999, 0.046875, 0.734375)\n","870 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","880 step train acc     : (0.703125, 0.078125, 0.78125)\n","890 step train acc     : (0.740625, 0.046875, 0.84375)\n","900 step train acc     : (0.7109375, 0.09375, 0.78125)\n","910 step train acc     : (0.7828125, 0.078125, 0.875)\n","920 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","930 step train acc     : (0.70078125, 0.046875, 0.796875)\n","940 step train acc     : (0.72421875, 0.09375, 0.796875)\n","950 step train acc     : (0.79296875, 0.125, 0.859375)\n","960 step train acc     : (0.7109375, 0.09375, 0.78125)\n","970 step train acc     : (0.703125, 0.078125, 0.78125)\n","980 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","990 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","1000 step train acc     : (0.7671875, 0.046875, 0.875)\n","====================================================================================================\n","0 step val acc     : (0.742919921875, 0.0830078125, 0.8251953125)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","1010 step train acc     : (0.73828125, 0.015625, 0.859375)\n","1020 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","1030 step train acc     : (0.73203125, 0.109375, 0.796875)\n","1040 step train acc     : (0.83828125, 0.109375, 0.921875)\n","1050 step train acc     : (0.771875, 0.109375, 0.84375)\n","1060 step train acc     : (0.76953125, 0.078125, 0.859375)\n","1070 step train acc     : (0.6945312499999999, 0.140625, 0.734375)\n","1080 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","1090 step train acc     : (0.6421875, 0.0625, 0.71875)\n","1100 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","1110 step train acc     : (0.7484375, 0.0625, 0.84375)\n","1120 step train acc     : (0.75625, 0.078125, 0.84375)\n","1130 step train acc     : (0.71328125, 0.125, 0.765625)\n","1140 step train acc     : (0.771875, 0.109375, 0.84375)\n","1150 step train acc     : (0.75078125, 0.09375, 0.828125)\n","1160 step train acc     : (0.75546875, 0.15625, 0.796875)\n","1170 step train acc     : (0.73984375, 0.125, 0.796875)\n","1180 step train acc     : (0.8109375, 0.1875, 0.84375)\n","1190 step train acc     : (0.7484375, 0.0625, 0.84375)\n","1200 step train acc     : (0.665625, 0.109375, 0.71875)\n","1210 step train acc     : (0.8171875, 0.09375, 0.90625)\n","1220 step train acc     : (0.6953125, 0.0625, 0.78125)\n","1230 step train acc     : (0.65234375, 0.109375, 0.703125)\n","1240 step train acc     : (0.75859375, 0.109375, 0.828125)\n","1250 step train acc     : (0.69765625, 0.09375, 0.765625)\n","1260 step train acc     : (0.73515625, 0.0625, 0.828125)\n","1270 step train acc     : (0.75078125, 0.09375, 0.828125)\n","1280 step train acc     : (0.75859375, 0.109375, 0.828125)\n","1290 step train acc     : (0.8171875, 0.09375, 0.90625)\n","1300 step train acc     : (0.77421875, 0.140625, 0.828125)\n","1310 step train acc     : (0.671875, 0.015625, 0.78125)\n","1320 step train acc     : (0.775, 0.0625, 0.875)\n","1330 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","1340 step train acc     : (0.75625, 0.078125, 0.84375)\n","1350 step train acc     : (0.72109375, 0.140625, 0.765625)\n","1360 step train acc     : (0.71640625, 0.078125, 0.796875)\n","1370 step train acc     : (0.71875, 0.109375, 0.78125)\n","1380 step train acc     : (0.6765625, 0.078125, 0.75)\n","1390 step train acc     : (0.7796875, 0.125, 0.84375)\n","1400 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","1410 step train acc     : (0.71640625, 0.078125, 0.796875)\n","1420 step train acc     : (0.803125, 0.171875, 0.84375)\n","1430 step train acc     : (0.7671875, 0.046875, 0.875)\n","1440 step train acc     : (0.825, 0.109375, 0.90625)\n","1450 step train acc     : (0.6953125, 0.0625, 0.78125)\n","1460 step train acc     : (0.6984374999999999, 0.015625, 0.8125)\n","1470 step train acc     : (0.715625, 0.15625, 0.75)\n","1480 step train acc     : (0.73515625, 0.0625, 0.828125)\n","1490 step train acc     : (0.68203125, 0.0625, 0.765625)\n","1500 step train acc     : (0.76953125, 0.078125, 0.859375)\n","1510 step train acc     : (0.70859375, 0.0625, 0.796875)\n","1520 step train acc     : (0.68984375, 0.078125, 0.765625)\n","1530 step train acc     : (0.6953125, 0.0625, 0.78125)\n","1540 step train acc     : (0.71640625, 0.078125, 0.796875)\n","1550 step train acc     : (0.8171875, 0.09375, 0.90625)\n","1560 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","1570 step train acc     : (0.75078125, 0.09375, 0.828125)\n","1580 step train acc     : (0.71171875, 0.015625, 0.828125)\n","1590 step train acc     : (0.73515625, 0.0625, 0.828125)\n","1600 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","1610 step train acc     : (0.68125, 0.140625, 0.71875)\n","1620 step train acc     : (0.75078125, 0.09375, 0.828125)\n","1630 step train acc     : (0.84609375, 0.125, 0.921875)\n","1640 step train acc     : (0.71953125, 0.03125, 0.828125)\n","1650 step train acc     : (0.70078125, 0.046875, 0.796875)\n","1660 step train acc     : (0.68984375, 0.078125, 0.765625)\n","1670 step train acc     : (0.73203125, 0.109375, 0.796875)\n","1680 step train acc     : (0.63671875, 0.078125, 0.703125)\n","1690 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","1700 step train acc     : (0.75390625, 0.046875, 0.859375)\n","1710 step train acc     : (0.83046875, 0.09375, 0.921875)\n","1720 step train acc     : (0.7484375, 0.0625, 0.84375)\n","1730 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","1740 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","1750 step train acc     : (0.73203125, 0.109375, 0.796875)\n","1760 step train acc     : (0.72734375, 0.046875, 0.828125)\n","1770 step train acc     : (0.7671875, 0.046875, 0.875)\n","1780 step train acc     : (0.75625, 0.078125, 0.84375)\n","1790 step train acc     : (0.653125, 0.03125, 0.75)\n","1800 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","1810 step train acc     : (0.76953125, 0.078125, 0.859375)\n","1820 step train acc     : (0.77734375, 0.09375, 0.859375)\n","1830 step train acc     : (0.6796875, 0.03125, 0.78125)\n","1840 step train acc     : (0.7828125, 0.078125, 0.875)\n","1850 step train acc     : (0.78515625, 0.109375, 0.859375)\n","1860 step train acc     : (0.740625, 0.046875, 0.84375)\n","1870 step train acc     : (0.8640625, 0.1875, 0.90625)\n","1880 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","1890 step train acc     : (0.7843749999999999, 0.1875, 0.8125)\n","1900 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","1910 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","1920 step train acc     : (0.7875, 0.140625, 0.84375)\n","1930 step train acc     : (0.82265625, 0.078125, 0.921875)\n","1940 step train acc     : (0.79296875, 0.125, 0.859375)\n","1950 step train acc     : (0.821875, 0.15625, 0.875)\n","1960 step train acc     : (0.75078125, 0.09375, 0.828125)\n","1970 step train acc     : (0.75859375, 0.109375, 0.828125)\n","1980 step train acc     : (0.6632812499999999, 0.078125, 0.734375)\n","1990 step train acc     : (0.74296875, 0.078125, 0.828125)\n","2000 step train acc     : (0.8015625, 0.0625, 0.90625)\n","====================================================================================================\n","0 step val acc     : (0.73447265625, 0.0810546875, 0.81640625)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","2010 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","2020 step train acc     : (0.76640625, 0.125, 0.828125)\n","2030 step train acc     : (0.69765625, 0.09375, 0.765625)\n","2040 step train acc     : (0.7640625, 0.09375, 0.84375)\n","2050 step train acc     : (0.77734375, 0.09375, 0.859375)\n","2060 step train acc     : (0.70859375, 0.0625, 0.796875)\n","2070 step train acc     : (0.79375, 0.046875, 0.90625)\n","2080 step train acc     : (0.6875, 0.046875, 0.78125)\n","2090 step train acc     : (0.8109375, 0.1875, 0.84375)\n","2100 step train acc     : (0.8484375, 0.15625, 0.90625)\n","2110 step train acc     : (0.7421875, 0.15625, 0.78125)\n","2120 step train acc     : (0.74765625, 0.140625, 0.796875)\n","2130 step train acc     : (0.7875, 0.140625, 0.84375)\n","2140 step train acc     : (0.76640625, 0.125, 0.828125)\n","2150 step train acc     : (0.75078125, 0.09375, 0.828125)\n","2160 step train acc     : (0.71953125, 0.03125, 0.828125)\n","2170 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","2180 step train acc     : (0.775, 0.0625, 0.875)\n","2190 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2200 step train acc     : (0.7726562499999999, 0.03125, 0.890625)\n","2210 step train acc     : (0.8015625, 0.0625, 0.90625)\n","2220 step train acc     : (0.7828125, 0.078125, 0.875)\n","2230 step train acc     : (0.75625, 0.078125, 0.84375)\n","2240 step train acc     : (0.70859375, 0.0625, 0.796875)\n","2250 step train acc     : (0.74296875, 0.078125, 0.828125)\n","2260 step train acc     : (0.734375, 0.140625, 0.78125)\n","2270 step train acc     : (0.8359375, 0.078125, 0.9375)\n","2280 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","2290 step train acc     : (0.66640625, 0.03125, 0.765625)\n","2300 step train acc     : (0.7953125, 0.15625, 0.84375)\n","2310 step train acc     : (0.76640625, 0.125, 0.828125)\n","2320 step train acc     : (0.7328125, 0.03125, 0.84375)\n","2330 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","2340 step train acc     : (0.80703125, 0.046875, 0.921875)\n","2350 step train acc     : (0.74296875, 0.078125, 0.828125)\n","2360 step train acc     : (0.790625, 0.09375, 0.875)\n","2370 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","2380 step train acc     : (0.740625, 0.046875, 0.84375)\n","2390 step train acc     : (0.684375, 0.09375, 0.75)\n","2400 step train acc     : (0.7640625, 0.09375, 0.84375)\n","2410 step train acc     : (0.78515625, 0.109375, 0.859375)\n","2420 step train acc     : (0.61796875, 0.09375, 0.671875)\n","2430 step train acc     : (0.8171875, 0.09375, 0.90625)\n","2440 step train acc     : (0.840625, 0.140625, 0.90625)\n","2450 step train acc     : (0.73203125, 0.109375, 0.796875)\n","2460 step train acc     : (0.78203125, 0.15625, 0.828125)\n","2470 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","2480 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2490 step train acc     : (0.7726562499999999, 0.03125, 0.890625)\n","2500 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","2510 step train acc     : (0.72734375, 0.046875, 0.828125)\n","2520 step train acc     : (0.76640625, 0.125, 0.828125)\n","2530 step train acc     : (0.821875, 0.15625, 0.875)\n","2540 step train acc     : (0.68203125, 0.0625, 0.765625)\n","2550 step train acc     : (0.71953125, 0.03125, 0.828125)\n","2560 step train acc     : (0.6765625, 0.078125, 0.75)\n","2570 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","2580 step train acc     : (0.7984375, 0.109375, 0.875)\n","2590 step train acc     : (0.72734375, 0.046875, 0.828125)\n","2600 step train acc     : (0.75625, 0.078125, 0.84375)\n","2610 step train acc     : (0.76171875, 0.0625, 0.859375)\n","2620 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","2630 step train acc     : (0.703125, 0.078125, 0.78125)\n","2640 step train acc     : (0.83046875, 0.09375, 0.921875)\n","2650 step train acc     : (0.7062499999999999, 0.03125, 0.8125)\n","2660 step train acc     : (0.72734375, 0.046875, 0.828125)\n","2670 step train acc     : (0.790625, 0.09375, 0.875)\n","2680 step train acc     : (0.6554687499999999, 0.0625, 0.734375)\n","2690 step train acc     : (0.72421875, 0.09375, 0.796875)\n","2700 step train acc     : (0.68203125, 0.0625, 0.765625)\n","2710 step train acc     : (0.84609375, 0.125, 0.921875)\n","2720 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","2730 step train acc     : (0.70859375, 0.0625, 0.796875)\n","2740 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","2750 step train acc     : (0.740625, 0.046875, 0.84375)\n","2760 step train acc     : (0.809375, 0.078125, 0.90625)\n","2770 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","2780 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","2790 step train acc     : (0.7984375, 0.109375, 0.875)\n","2800 step train acc     : (0.8171875, 0.09375, 0.90625)\n","2810 step train acc     : (0.7484375, 0.0625, 0.84375)\n","2820 step train acc     : (0.7671875, 0.046875, 0.875)\n","2830 step train acc     : (0.71640625, 0.078125, 0.796875)\n","2840 step train acc     : (0.70859375, 0.0625, 0.796875)\n","2850 step train acc     : (0.75859375, 0.109375, 0.828125)\n","2860 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","2870 step train acc     : (0.740625, 0.046875, 0.84375)\n","2880 step train acc     : (0.7171875, 0.0, 0.84375)\n","2890 step train acc     : (0.7796875, 0.125, 0.84375)\n","2900 step train acc     : (0.7726562499999999, 0.03125, 0.890625)\n","2910 step train acc     : (0.70078125, 0.046875, 0.796875)\n","2920 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","2930 step train acc     : (0.76953125, 0.078125, 0.859375)\n","2940 step train acc     : (0.8140625, 0.140625, 0.875)\n","2950 step train acc     : (0.72734375, 0.046875, 0.828125)\n","2960 step train acc     : (0.76171875, 0.0625, 0.859375)\n","2970 step train acc     : (0.77421875, 0.140625, 0.828125)\n","2980 step train acc     : (0.6554687499999999, 0.0625, 0.734375)\n","2990 step train acc     : (0.8375, 0.1875, 0.875)\n","3000 step train acc     : (0.7640625, 0.09375, 0.84375)\n","====================================================================================================\n","0 step val acc     : (0.73642578125, 0.0849609375, 0.81640625)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","3010 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","3020 step train acc     : (0.7109375, 0.09375, 0.78125)\n","3030 step train acc     : (0.74296875, 0.078125, 0.828125)\n","3040 step train acc     : (0.73984375, 0.125, 0.796875)\n","3050 step train acc     : (0.6953125, 0.0625, 0.78125)\n","3060 step train acc     : (0.71171875, 0.015625, 0.828125)\n","3070 step train acc     : (0.76171875, 0.0625, 0.859375)\n","3080 step train acc     : (0.7828125, 0.078125, 0.875)\n","3090 step train acc     : (0.72421875, 0.09375, 0.796875)\n","3100 step train acc     : (0.79296875, 0.125, 0.859375)\n","3110 step train acc     : (0.8171875, 0.09375, 0.90625)\n","3120 step train acc     : (0.86484375, 0.109375, 0.953125)\n","3130 step train acc     : (0.71875, 0.109375, 0.78125)\n","3140 step train acc     : (0.6921875, 0.109375, 0.75)\n","3150 step train acc     : (0.703125, 0.078125, 0.78125)\n","3160 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","3170 step train acc     : (0.775, 0.0625, 0.875)\n","3180 step train acc     : (0.703125, 0.078125, 0.78125)\n","3190 step train acc     : (0.775, 0.0625, 0.875)\n","3200 step train acc     : (0.74375, 0.0, 0.875)\n","3210 step train acc     : (0.6945312499999999, 0.140625, 0.734375)\n","3220 step train acc     : (0.73515625, 0.0625, 0.828125)\n","3230 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3240 step train acc     : (0.70859375, 0.0625, 0.796875)\n","3250 step train acc     : (0.75078125, 0.09375, 0.828125)\n","3260 step train acc     : (0.765625, 0.203125, 0.78125)\n","3270 step train acc     : (0.7984375, 0.109375, 0.875)\n","3280 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","3290 step train acc     : (0.8195312499999999, 0.125, 0.890625)\n","3300 step train acc     : (0.6632812499999999, 0.078125, 0.734375)\n","3310 step train acc     : (0.75859375, 0.109375, 0.828125)\n","3320 step train acc     : (0.81640625, 0.171875, 0.859375)\n","3330 step train acc     : (0.77734375, 0.09375, 0.859375)\n","3340 step train acc     : (0.80078125, 0.140625, 0.859375)\n","3350 step train acc     : (0.80625, 0.125, 0.875)\n","3360 step train acc     : (0.77734375, 0.09375, 0.859375)\n","3370 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","3380 step train acc     : (0.80078125, 0.140625, 0.859375)\n","3390 step train acc     : (0.759375, 0.03125, 0.875)\n","3400 step train acc     : (0.79296875, 0.125, 0.859375)\n","3410 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","3420 step train acc     : (0.74296875, 0.078125, 0.828125)\n","3430 step train acc     : (0.68984375, 0.078125, 0.765625)\n","3440 step train acc     : (0.8671875, 0.140625, 0.9375)\n","3450 step train acc     : (0.6875, 0.046875, 0.78125)\n","3460 step train acc     : (0.7671875, 0.046875, 0.875)\n","3470 step train acc     : (0.70546875, 0.109375, 0.765625)\n","3480 step train acc     : (0.80859375, 0.15625, 0.859375)\n","3490 step train acc     : (0.7828125, 0.078125, 0.875)\n","3500 step train acc     : (0.7953125, 0.15625, 0.84375)\n","3510 step train acc     : (0.82265625, 0.078125, 0.921875)\n","3520 step train acc     : (0.76640625, 0.125, 0.828125)\n","3530 step train acc     : (0.73203125, 0.109375, 0.796875)\n","3540 step train acc     : (0.74296875, 0.078125, 0.828125)\n","3550 step train acc     : (0.71640625, 0.078125, 0.796875)\n","3560 step train acc     : (0.85625, 0.171875, 0.90625)\n","3570 step train acc     : (0.75078125, 0.09375, 0.828125)\n","3580 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","3590 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","3600 step train acc     : (0.78203125, 0.15625, 0.828125)\n","3610 step train acc     : (0.790625, 0.09375, 0.875)\n","3620 step train acc     : (0.6953125, 0.0625, 0.78125)\n","3630 step train acc     : (0.665625, 0.109375, 0.71875)\n","3640 step train acc     : (0.76171875, 0.0625, 0.859375)\n","3650 step train acc     : (0.84140625, 0.0625, 0.953125)\n","3660 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","3670 step train acc     : (0.83828125, 0.109375, 0.921875)\n","3680 step train acc     : (0.78515625, 0.109375, 0.859375)\n","3690 step train acc     : (0.76328125, 0.171875, 0.796875)\n","3700 step train acc     : (0.6765625, 0.078125, 0.75)\n","3710 step train acc     : (0.6554687499999999, 0.0625, 0.734375)\n","3720 step train acc     : (0.68203125, 0.0625, 0.765625)\n","3730 step train acc     : (0.76328125, 0.171875, 0.796875)\n","3740 step train acc     : (0.7265625, 0.125, 0.78125)\n","3750 step train acc     : (0.83203125, 0.203125, 0.859375)\n","3760 step train acc     : (0.73515625, 0.0625, 0.828125)\n","3770 step train acc     : (0.8640625, 0.1875, 0.90625)\n","3780 step train acc     : (0.7796875, 0.125, 0.84375)\n","3790 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","3800 step train acc     : (0.71875, 0.109375, 0.78125)\n","3810 step train acc     : (0.7640625, 0.09375, 0.84375)\n","3820 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","3830 step train acc     : (0.80625, 0.125, 0.875)\n","3840 step train acc     : (0.71875, 0.109375, 0.78125)\n","3850 step train acc     : (0.6320312499999999, 0.015625, 0.734375)\n","3860 step train acc     : (0.703125, 0.078125, 0.78125)\n","3870 step train acc     : (0.80859375, 0.15625, 0.859375)\n","3880 step train acc     : (0.71875, 0.109375, 0.78125)\n","3890 step train acc     : (0.7484375, 0.0625, 0.84375)\n","3900 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","3910 step train acc     : (0.77734375, 0.09375, 0.859375)\n","3920 step train acc     : (0.76953125, 0.078125, 0.859375)\n","3930 step train acc     : (0.73515625, 0.0625, 0.828125)\n","3940 step train acc     : (0.68203125, 0.0625, 0.765625)\n","3950 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3960 step train acc     : (0.76171875, 0.0625, 0.859375)\n","3970 step train acc     : (0.72734375, 0.046875, 0.828125)\n","3980 step train acc     : (0.72734375, 0.046875, 0.828125)\n","3990 step train acc     : (0.7640625, 0.09375, 0.84375)\n","4000 step train acc     : (0.7796875, 0.125, 0.84375)\n","====================================================================================================\n","0 step val acc     : (0.721044921875, 0.0791015625, 0.8017578125)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","4010 step train acc     : (0.71640625, 0.078125, 0.796875)\n","4020 step train acc     : (0.7796875, 0.125, 0.84375)\n","4030 step train acc     : (0.6953125, 0.0625, 0.78125)\n","4040 step train acc     : (0.76953125, 0.078125, 0.859375)\n","4050 step train acc     : (0.66875, 0.0625, 0.75)\n","4060 step train acc     : (0.703125, 0.078125, 0.78125)\n","4070 step train acc     : (0.734375, 0.140625, 0.78125)\n","4080 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","4090 step train acc     : (0.64453125, 0.09375, 0.703125)\n","4100 step train acc     : (0.6921875, 0.109375, 0.75)\n","4110 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","4120 step train acc     : (0.6765625, 0.078125, 0.75)\n","4130 step train acc     : (0.75078125, 0.09375, 0.828125)\n","4140 step train acc     : (0.7828125, 0.078125, 0.875)\n","4150 step train acc     : (0.7875, 0.140625, 0.84375)\n","4160 step train acc     : (0.72890625, 0.15625, 0.765625)\n","4170 step train acc     : (0.775, 0.0625, 0.875)\n","4180 step train acc     : (0.79296875, 0.125, 0.859375)\n","4190 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","4200 step train acc     : (0.76328125, 0.171875, 0.796875)\n","4210 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","4220 step train acc     : (0.7078125, 0.140625, 0.75)\n","4230 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","4240 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","4250 step train acc     : (0.75078125, 0.09375, 0.828125)\n","4260 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","4270 step train acc     : (0.86484375, 0.109375, 0.953125)\n","4280 step train acc     : (0.89140625, 0.109375, 0.984375)\n","4290 step train acc     : (0.75859375, 0.109375, 0.828125)\n","4300 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","4310 step train acc     : (0.71640625, 0.078125, 0.796875)\n","4320 step train acc     : (0.76171875, 0.0625, 0.859375)\n","4330 step train acc     : (0.61796875, 0.09375, 0.671875)\n","4340 step train acc     : (0.70859375, 0.0625, 0.796875)\n","4350 step train acc     : (0.73203125, 0.109375, 0.796875)\n","4360 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","4370 step train acc     : (0.73515625, 0.0625, 0.828125)\n","4380 step train acc     : (0.77734375, 0.09375, 0.859375)\n","4390 step train acc     : (0.80859375, 0.15625, 0.859375)\n","4400 step train acc     : (0.78984375, 0.171875, 0.828125)\n","4410 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","4420 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","4430 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","4440 step train acc     : (0.80625, 0.125, 0.875)\n","4450 step train acc     : (0.71640625, 0.078125, 0.796875)\n","4460 step train acc     : (0.78515625, 0.109375, 0.859375)\n","4470 step train acc     : (0.76171875, 0.0625, 0.859375)\n","4480 step train acc     : (0.77421875, 0.140625, 0.828125)\n","4490 step train acc     : (0.79296875, 0.125, 0.859375)\n","4500 step train acc     : (0.7640625, 0.09375, 0.84375)\n","4510 step train acc     : (0.77734375, 0.09375, 0.859375)\n","4520 step train acc     : (0.75625, 0.078125, 0.84375)\n","4530 step train acc     : (0.74296875, 0.078125, 0.828125)\n","4540 step train acc     : (0.76640625, 0.125, 0.828125)\n","4550 step train acc     : (0.8015625, 0.0625, 0.90625)\n","4560 step train acc     : (0.6867187499999999, 0.125, 0.734375)\n","4570 step train acc     : (0.77734375, 0.09375, 0.859375)\n","4580 step train acc     : (0.71328125, 0.125, 0.765625)\n","4590 step train acc     : (0.809375, 0.078125, 0.90625)\n","4600 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","4610 step train acc     : (0.76171875, 0.0625, 0.859375)\n","4620 step train acc     : (0.771875, 0.109375, 0.84375)\n","4630 step train acc     : (0.71875, 0.109375, 0.78125)\n","4640 step train acc     : (0.8328125, 0.125, 0.90625)\n","4650 step train acc     : (0.75625, 0.078125, 0.84375)\n","4660 step train acc     : (0.71875, 0.109375, 0.78125)\n","4670 step train acc     : (0.7, 0.125, 0.75)\n","4680 step train acc     : (0.76171875, 0.0625, 0.859375)\n","4690 step train acc     : (0.7109375, 0.09375, 0.78125)\n","4700 step train acc     : (0.7687499999999999, 0.15625, 0.8125)\n","4710 step train acc     : (0.82421875, 0.1875, 0.859375)\n","4720 step train acc     : (0.70546875, 0.109375, 0.765625)\n","4730 step train acc     : (0.7328125, 0.03125, 0.84375)\n","4740 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","4750 step train acc     : (0.7640625, 0.09375, 0.84375)\n","4760 step train acc     : (0.75625, 0.078125, 0.84375)\n","4770 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","4780 step train acc     : (0.825, 0.109375, 0.90625)\n","4790 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","4800 step train acc     : (0.68203125, 0.0625, 0.765625)\n","4810 step train acc     : (0.6765625, 0.078125, 0.75)\n","4820 step train acc     : (0.70546875, 0.109375, 0.765625)\n","4830 step train acc     : (0.65, 0.078125, 0.71875)\n","4840 step train acc     : (0.79296875, 0.125, 0.859375)\n","4850 step train acc     : (0.78203125, 0.15625, 0.828125)\n","4860 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","4870 step train acc     : (0.759375, 0.03125, 0.875)\n","4880 step train acc     : (0.75625, 0.078125, 0.84375)\n","4890 step train acc     : (0.7984375, 0.109375, 0.875)\n","4900 step train acc     : (0.790625, 0.09375, 0.875)\n","4910 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","4920 step train acc     : (0.76171875, 0.0625, 0.859375)\n","4930 step train acc     : (0.7484375, 0.0625, 0.84375)\n","4940 step train acc     : (0.86171875, 0.15625, 0.921875)\n","4950 step train acc     : (0.77734375, 0.09375, 0.859375)\n","4960 step train acc     : (0.77109375, 0.1875, 0.796875)\n","4970 step train acc     : (0.73984375, 0.125, 0.796875)\n","4980 step train acc     : (0.775, 0.0625, 0.875)\n","4990 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","5000 step train acc     : (0.79765625, 0.1875, 0.828125)\n","====================================================================================================\n","0 step val acc     : (0.737890625, 0.087890625, 0.81640625)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","5010 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","5020 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","5030 step train acc     : (0.7109375, 0.09375, 0.78125)\n","5040 step train acc     : (0.83828125, 0.109375, 0.921875)\n","5050 step train acc     : (0.76953125, 0.078125, 0.859375)\n","5060 step train acc     : (0.79375, 0.046875, 0.90625)\n","5070 step train acc     : (0.71875, 0.109375, 0.78125)\n","5080 step train acc     : (0.76171875, 0.0625, 0.859375)\n","5090 step train acc     : (0.7265625, 0.125, 0.78125)\n","5100 step train acc     : (0.77421875, 0.140625, 0.828125)\n","5110 step train acc     : (0.79296875, 0.125, 0.859375)\n","5120 step train acc     : (0.75625, 0.078125, 0.84375)\n","5130 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","5140 step train acc     : (0.77734375, 0.09375, 0.859375)\n","5150 step train acc     : (0.71640625, 0.078125, 0.796875)\n","5160 step train acc     : (0.7828125, 0.078125, 0.875)\n","5170 step train acc     : (0.72734375, 0.046875, 0.828125)\n","5180 step train acc     : (0.703125, 0.078125, 0.78125)\n","5190 step train acc     : (0.6875, 0.046875, 0.78125)\n","5200 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","5210 step train acc     : (0.75625, 0.078125, 0.84375)\n","5220 step train acc     : (0.73203125, 0.109375, 0.796875)\n","5230 step train acc     : (0.77734375, 0.09375, 0.859375)\n","5240 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","5250 step train acc     : (0.6421875, 0.0625, 0.71875)\n","5260 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","5270 step train acc     : (0.89140625, 0.109375, 0.984375)\n","5280 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","5290 step train acc     : (0.6953125, 0.0625, 0.78125)\n","5300 step train acc     : (0.859375, 0.125, 0.9375)\n","5310 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","5320 step train acc     : (0.7484375, 0.0625, 0.84375)\n","5330 step train acc     : (0.70859375, 0.0625, 0.796875)\n","5340 step train acc     : (0.83828125, 0.109375, 0.921875)\n","5350 step train acc     : (0.703125, 0.078125, 0.78125)\n","5360 step train acc     : (0.77421875, 0.140625, 0.828125)\n","5370 step train acc     : (0.7921874999999999, 0.203125, 0.8125)\n","5380 step train acc     : (0.75078125, 0.09375, 0.828125)\n","5390 step train acc     : (0.72421875, 0.09375, 0.796875)\n","5400 step train acc     : (0.77734375, 0.09375, 0.859375)\n","5410 step train acc     : (0.73515625, 0.0625, 0.828125)\n","5420 step train acc     : (0.75859375, 0.109375, 0.828125)\n","5430 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","5440 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","5450 step train acc     : (0.7484375, 0.0625, 0.84375)\n","5460 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","5470 step train acc     : (0.809375, 0.078125, 0.90625)\n","5480 step train acc     : (0.76171875, 0.0625, 0.859375)\n","5490 step train acc     : (0.75625, 0.078125, 0.84375)\n","5500 step train acc     : (0.7875, 0.140625, 0.84375)\n","5510 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","5520 step train acc     : (0.75859375, 0.109375, 0.828125)\n","5530 step train acc     : (0.7984375, 0.109375, 0.875)\n","5540 step train acc     : (0.70078125, 0.046875, 0.796875)\n","5550 step train acc     : (0.7796875, 0.125, 0.84375)\n","5560 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","5570 step train acc     : (0.7265625, 0.125, 0.78125)\n","5580 step train acc     : (0.74609375, 0.03125, 0.859375)\n","5590 step train acc     : (0.72734375, 0.046875, 0.828125)\n","5600 step train acc     : (0.70859375, 0.0625, 0.796875)\n","5610 step train acc     : (0.76953125, 0.078125, 0.859375)\n","5620 step train acc     : (0.79375, 0.046875, 0.90625)\n","5630 step train acc     : (0.68984375, 0.078125, 0.765625)\n","5640 step train acc     : (0.809375, 0.078125, 0.90625)\n","5650 step train acc     : (0.7843749999999999, 0.1875, 0.8125)\n","5660 step train acc     : (0.78984375, 0.171875, 0.828125)\n","5670 step train acc     : (0.76953125, 0.078125, 0.859375)\n","5680 step train acc     : (0.6609375, 0.046875, 0.75)\n","5690 step train acc     : (0.73515625, 0.0625, 0.828125)\n","5700 step train acc     : (0.68984375, 0.078125, 0.765625)\n","5710 step train acc     : (0.7859375, 0.03125, 0.90625)\n","5720 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","5730 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","5740 step train acc     : (0.79765625, 0.1875, 0.828125)\n","5750 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","5760 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","5770 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","5780 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","5790 step train acc     : (0.7671875, 0.046875, 0.875)\n","5800 step train acc     : (0.77734375, 0.09375, 0.859375)\n","5810 step train acc     : (0.75859375, 0.109375, 0.828125)\n","5820 step train acc     : (0.684375, 0.09375, 0.75)\n","5830 step train acc     : (0.671875, 0.015625, 0.78125)\n","5840 step train acc     : (0.83046875, 0.09375, 0.921875)\n","5850 step train acc     : (0.7640625, 0.09375, 0.84375)\n","5860 step train acc     : (0.75625, 0.078125, 0.84375)\n","5870 step train acc     : (0.72890625, 0.15625, 0.765625)\n","5880 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","5890 step train acc     : (0.809375, 0.078125, 0.90625)\n","5900 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","5910 step train acc     : (0.76953125, 0.078125, 0.859375)\n","5920 step train acc     : (0.7, 0.125, 0.75)\n","5930 step train acc     : (0.78515625, 0.109375, 0.859375)\n","5940 step train acc     : (0.84609375, 0.125, 0.921875)\n","5950 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","5960 step train acc     : (0.7640625, 0.09375, 0.84375)\n","5970 step train acc     : (0.7484375, 0.0625, 0.84375)\n","5980 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","5990 step train acc     : (0.79296875, 0.125, 0.859375)\n","6000 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","====================================================================================================\n","0 step val acc     : (0.73671875, 0.072265625, 0.82421875)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","6010 step train acc     : (0.83828125, 0.109375, 0.921875)\n","6020 step train acc     : (0.76171875, 0.0625, 0.859375)\n","6030 step train acc     : (0.734375, 0.140625, 0.78125)\n","6040 step train acc     : (0.809375, 0.078125, 0.90625)\n","6050 step train acc     : (0.74296875, 0.078125, 0.828125)\n","6060 step train acc     : (0.76640625, 0.125, 0.828125)\n","6070 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","6080 step train acc     : (0.76171875, 0.0625, 0.859375)\n","6090 step train acc     : (0.734375, 0.140625, 0.78125)\n","6100 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","6110 step train acc     : (0.665625, 0.109375, 0.71875)\n","6120 step train acc     : (0.684375, 0.09375, 0.75)\n","6130 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","6140 step train acc     : (0.7984375, 0.109375, 0.875)\n","6150 step train acc     : (0.759375, 0.03125, 0.875)\n","6160 step train acc     : (0.8195312499999999, 0.125, 0.890625)\n","6170 step train acc     : (0.83046875, 0.09375, 0.921875)\n","6180 step train acc     : (0.7687499999999999, 0.15625, 0.8125)\n","6190 step train acc     : (0.70859375, 0.0625, 0.796875)\n","6200 step train acc     : (0.76171875, 0.0625, 0.859375)\n","6210 step train acc     : (0.76953125, 0.078125, 0.859375)\n","6220 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","6230 step train acc     : (0.7640625, 0.09375, 0.84375)\n","6240 step train acc     : (0.790625, 0.09375, 0.875)\n","6250 step train acc     : (0.75078125, 0.09375, 0.828125)\n","6260 step train acc     : (0.771875, 0.109375, 0.84375)\n","6270 step train acc     : (0.76953125, 0.078125, 0.859375)\n","6280 step train acc     : (0.68203125, 0.0625, 0.765625)\n","6290 step train acc     : (0.8429687499999999, 0.171875, 0.890625)\n","6300 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","6310 step train acc     : (0.79921875, 0.03125, 0.921875)\n","6320 step train acc     : (0.734375, 0.140625, 0.78125)\n","6330 step train acc     : (0.8140625, 0.140625, 0.875)\n","6340 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","6350 step train acc     : (0.7828125, 0.078125, 0.875)\n","6360 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","6370 step train acc     : (0.771875, 0.109375, 0.84375)\n","6380 step train acc     : (0.73515625, 0.0625, 0.828125)\n","6390 step train acc     : (0.703125, 0.078125, 0.78125)\n","6400 step train acc     : (0.73515625, 0.0625, 0.828125)\n","6410 step train acc     : (0.74765625, 0.140625, 0.796875)\n","6420 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","6430 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","6440 step train acc     : (0.7671875, 0.046875, 0.875)\n","6450 step train acc     : (0.6609375, 0.046875, 0.75)\n","6460 step train acc     : (0.6578125, 0.09375, 0.71875)\n","6470 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","6480 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","6490 step train acc     : (0.74765625, 0.140625, 0.796875)\n","6500 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","6510 step train acc     : (0.75859375, 0.109375, 0.828125)\n","6520 step train acc     : (0.75625, 0.078125, 0.84375)\n","6530 step train acc     : (0.79296875, 0.125, 0.859375)\n","6540 step train acc     : (0.72421875, 0.09375, 0.796875)\n","6550 step train acc     : (0.70859375, 0.0625, 0.796875)\n","6560 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","6570 step train acc     : (0.790625, 0.09375, 0.875)\n","6580 step train acc     : (0.7328125, 0.03125, 0.84375)\n","6590 step train acc     : (0.8195312499999999, 0.125, 0.890625)\n","6600 step train acc     : (0.86484375, 0.109375, 0.953125)\n","6610 step train acc     : (0.771875, 0.109375, 0.84375)\n","6620 step train acc     : (0.76953125, 0.078125, 0.859375)\n","6630 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","6640 step train acc     : (0.80703125, 0.046875, 0.921875)\n","6650 step train acc     : (0.7640625, 0.09375, 0.84375)\n","6660 step train acc     : (0.77734375, 0.09375, 0.859375)\n","6670 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","6680 step train acc     : (0.6875, 0.046875, 0.78125)\n","6690 step train acc     : (0.79375, 0.046875, 0.90625)\n","6700 step train acc     : (0.7726562499999999, 0.03125, 0.890625)\n","6710 step train acc     : (0.8640625, 0.1875, 0.90625)\n","6720 step train acc     : (0.8859374999999999, 0.125, 0.96875)\n","6730 step train acc     : (0.7484375, 0.0625, 0.84375)\n","6740 step train acc     : (0.76640625, 0.125, 0.828125)\n","6750 step train acc     : (0.76640625, 0.125, 0.828125)\n","6760 step train acc     : (0.76171875, 0.0625, 0.859375)\n","6770 step train acc     : (0.74765625, 0.140625, 0.796875)\n","6780 step train acc     : (0.775, 0.0625, 0.875)\n","6790 step train acc     : (0.71875, 0.109375, 0.78125)\n","6800 step train acc     : (0.7109375, 0.09375, 0.78125)\n","6810 step train acc     : (0.74765625, 0.140625, 0.796875)\n","6820 step train acc     : (0.809375, 0.078125, 0.90625)\n","6830 step train acc     : (0.78203125, 0.15625, 0.828125)\n","6840 step train acc     : (0.73828125, 0.015625, 0.859375)\n","6850 step train acc     : (0.76171875, 0.0625, 0.859375)\n","6860 step train acc     : (0.68984375, 0.078125, 0.765625)\n","6870 step train acc     : (0.79296875, 0.125, 0.859375)\n","6880 step train acc     : (0.7726562499999999, 0.03125, 0.890625)\n","6890 step train acc     : (0.78515625, 0.109375, 0.859375)\n","6900 step train acc     : (0.6710937499999999, 0.09375, 0.734375)\n","6910 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","6920 step train acc     : (0.71953125, 0.03125, 0.828125)\n","6930 step train acc     : (0.825, 0.109375, 0.90625)\n","6940 step train acc     : (0.7640625, 0.09375, 0.84375)\n","6950 step train acc     : (0.68984375, 0.078125, 0.765625)\n","6960 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","6970 step train acc     : (0.76640625, 0.125, 0.828125)\n","6980 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","6990 step train acc     : (0.75625, 0.078125, 0.84375)\n","7000 step train acc     : (0.72421875, 0.09375, 0.796875)\n","====================================================================================================\n","0 step val acc     : (0.74716796875, 0.08984375, 0.826171875)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","7010 step train acc     : (0.76953125, 0.078125, 0.859375)\n","7020 step train acc     : (0.6421875, 0.0625, 0.71875)\n","7030 step train acc     : (0.71640625, 0.078125, 0.796875)\n","7036 step train acc     : (0.7795918367346939, 0.10204081632653061, 0.8571428571428571)\n","====================================================================================================\n","0 step val acc     : (0.739013671875, 0.0751953125, 0.8251953125)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","saving cust_model ...\n","1\n","0 step train acc     : (0.703125, 0.078125, 0.78125)\n","====================================================================================================\n","0 step val acc     : (0.73671875, 0.0888671875, 0.814453125)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","10 step train acc     : (0.7953125, 0.15625, 0.84375)\n","20 step train acc     : (0.6875, 0.046875, 0.78125)\n","30 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","40 step train acc     : (0.71328125, 0.125, 0.765625)\n","50 step train acc     : (0.7515625, 0.015625, 0.875)\n","60 step train acc     : (0.71875, 0.109375, 0.78125)\n","70 step train acc     : (0.6953125, 0.0625, 0.78125)\n","80 step train acc     : (0.81484375, 0.0625, 0.921875)\n","90 step train acc     : (0.76640625, 0.125, 0.828125)\n","100 step train acc     : (0.76953125, 0.078125, 0.859375)\n","110 step train acc     : (0.7796875, 0.125, 0.84375)\n","120 step train acc     : (0.7828125, 0.078125, 0.875)\n","130 step train acc     : (0.8171875, 0.09375, 0.90625)\n","140 step train acc     : (0.6632812499999999, 0.078125, 0.734375)\n","150 step train acc     : (0.703125, 0.078125, 0.78125)\n","160 step train acc     : (0.73515625, 0.0625, 0.828125)\n","170 step train acc     : (0.7640625, 0.09375, 0.84375)\n","180 step train acc     : (0.68984375, 0.078125, 0.765625)\n","190 step train acc     : (0.740625, 0.046875, 0.84375)\n","200 step train acc     : (0.74296875, 0.078125, 0.828125)\n","210 step train acc     : (0.7640625, 0.09375, 0.84375)\n","220 step train acc     : (0.8015625, 0.0625, 0.90625)\n","230 step train acc     : (0.80703125, 0.046875, 0.921875)\n","240 step train acc     : (0.6953125, 0.0625, 0.78125)\n","250 step train acc     : (0.7484375, 0.0625, 0.84375)\n","260 step train acc     : (0.77734375, 0.09375, 0.859375)\n","270 step train acc     : (0.74609375, 0.03125, 0.859375)\n","280 step train acc     : (0.809375, 0.078125, 0.90625)\n","290 step train acc     : (0.8296875, 0.171875, 0.875)\n","300 step train acc     : (0.809375, 0.078125, 0.90625)\n","310 step train acc     : (0.78515625, 0.109375, 0.859375)\n","320 step train acc     : (0.80625, 0.125, 0.875)\n","330 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","340 step train acc     : (0.7953125, 0.15625, 0.84375)\n","350 step train acc     : (0.8359375, 0.078125, 0.9375)\n","360 step train acc     : (0.7484375, 0.0625, 0.84375)\n","370 step train acc     : (0.7984375, 0.109375, 0.875)\n","380 step train acc     : (0.6632812499999999, 0.078125, 0.734375)\n","390 step train acc     : (0.6875, 0.046875, 0.78125)\n","400 step train acc     : (0.7828125, 0.078125, 0.875)\n","410 step train acc     : (0.75625, 0.078125, 0.84375)\n","420 step train acc     : (0.70859375, 0.0625, 0.796875)\n","430 step train acc     : (0.73203125, 0.109375, 0.796875)\n","440 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","450 step train acc     : (0.75078125, 0.09375, 0.828125)\n","460 step train acc     : (0.7828125, 0.078125, 0.875)\n","470 step train acc     : (0.75390625, 0.046875, 0.859375)\n","480 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","490 step train acc     : (0.7796875, 0.125, 0.84375)\n","500 step train acc     : (0.72421875, 0.09375, 0.796875)\n","510 step train acc     : (0.78515625, 0.109375, 0.859375)\n","520 step train acc     : (0.7671875, 0.046875, 0.875)\n","530 step train acc     : (0.759375, 0.03125, 0.875)\n","540 step train acc     : (0.7828125, 0.078125, 0.875)\n","550 step train acc     : (0.740625, 0.046875, 0.84375)\n","560 step train acc     : (0.775, 0.0625, 0.875)\n","570 step train acc     : (0.73515625, 0.0625, 0.828125)\n","580 step train acc     : (0.7859375, 0.03125, 0.90625)\n","590 step train acc     : (0.77421875, 0.140625, 0.828125)\n","600 step train acc     : (0.809375, 0.078125, 0.90625)\n","610 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","620 step train acc     : (0.79375, 0.046875, 0.90625)\n","630 step train acc     : (0.75625, 0.078125, 0.84375)\n","640 step train acc     : (0.7484375, 0.0625, 0.84375)\n","650 step train acc     : (0.86484375, 0.109375, 0.953125)\n","660 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","670 step train acc     : (0.75859375, 0.109375, 0.828125)\n","680 step train acc     : (0.7687499999999999, 0.15625, 0.8125)\n","690 step train acc     : (0.84375, 0.09375, 0.9375)\n","700 step train acc     : (0.75078125, 0.09375, 0.828125)\n","710 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","720 step train acc     : (0.73515625, 0.0625, 0.828125)\n","730 step train acc     : (0.80625, 0.125, 0.875)\n","740 step train acc     : (0.76171875, 0.0625, 0.859375)\n","750 step train acc     : (0.7484375, 0.0625, 0.84375)\n","760 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","770 step train acc     : (0.7828125, 0.078125, 0.875)\n","780 step train acc     : (0.86171875, 0.15625, 0.921875)\n","790 step train acc     : (0.75078125, 0.09375, 0.828125)\n","800 step train acc     : (0.78515625, 0.109375, 0.859375)\n","810 step train acc     : (0.809375, 0.078125, 0.90625)\n","820 step train acc     : (0.7484375, 0.0625, 0.84375)\n","830 step train acc     : (0.77734375, 0.09375, 0.859375)\n","840 step train acc     : (0.8375, 0.1875, 0.875)\n","850 step train acc     : (0.8140625, 0.140625, 0.875)\n","860 step train acc     : (0.75078125, 0.09375, 0.828125)\n","870 step train acc     : (0.79296875, 0.125, 0.859375)\n","880 step train acc     : (0.740625, 0.046875, 0.84375)\n","890 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","900 step train acc     : (0.771875, 0.109375, 0.84375)\n","910 step train acc     : (0.76171875, 0.0625, 0.859375)\n","920 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","930 step train acc     : (0.740625, 0.046875, 0.84375)\n","940 step train acc     : (0.7828125, 0.078125, 0.875)\n","950 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","960 step train acc     : (0.7328125, 0.03125, 0.84375)\n","970 step train acc     : (0.703125, 0.078125, 0.78125)\n","980 step train acc     : (0.75078125, 0.09375, 0.828125)\n","990 step train acc     : (0.7828125, 0.078125, 0.875)\n","1000 step train acc     : (0.73515625, 0.0625, 0.828125)\n","====================================================================================================\n","0 step val acc     : (0.744677734375, 0.08984375, 0.8232421875)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","1010 step train acc     : (0.8703124999999999, 0.09375, 0.96875)\n","1020 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","1030 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","1040 step train acc     : (0.85703125, 0.09375, 0.953125)\n","1050 step train acc     : (0.8351562499999999, 0.15625, 0.890625)\n","1060 step train acc     : (0.7671875, 0.046875, 0.875)\n","1070 step train acc     : (0.70859375, 0.0625, 0.796875)\n","1080 step train acc     : (0.771875, 0.109375, 0.84375)\n","1090 step train acc     : (0.66640625, 0.03125, 0.765625)\n","1100 step train acc     : (0.73984375, 0.125, 0.796875)\n","1110 step train acc     : (0.83828125, 0.109375, 0.921875)\n","1120 step train acc     : (0.77734375, 0.09375, 0.859375)\n","1130 step train acc     : (0.75859375, 0.109375, 0.828125)\n","1140 step train acc     : (0.7984375, 0.109375, 0.875)\n","1150 step train acc     : (0.84375, 0.09375, 0.9375)\n","1160 step train acc     : (0.803125, 0.171875, 0.84375)\n","1170 step train acc     : (0.75390625, 0.046875, 0.859375)\n","1180 step train acc     : (0.809375, 0.078125, 0.90625)\n","1190 step train acc     : (0.85390625, 0.140625, 0.921875)\n","1200 step train acc     : (0.6789062499999999, 0.109375, 0.734375)\n","1210 step train acc     : (0.7984375, 0.109375, 0.875)\n","1220 step train acc     : (0.85, 0.265625, 0.84375)\n","1230 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","1240 step train acc     : (0.7796875, 0.125, 0.84375)\n","1250 step train acc     : (0.73203125, 0.109375, 0.796875)\n","1260 step train acc     : (0.7796875, 0.125, 0.84375)\n","1270 step train acc     : (0.78515625, 0.109375, 0.859375)\n","1280 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","1290 step train acc     : (0.83828125, 0.109375, 0.921875)\n","1300 step train acc     : (0.8171875, 0.09375, 0.90625)\n","1310 step train acc     : (0.74296875, 0.078125, 0.828125)\n","1320 step train acc     : (0.84609375, 0.125, 0.921875)\n","1330 step train acc     : (0.790625, 0.09375, 0.875)\n","1340 step train acc     : (0.7671875, 0.046875, 0.875)\n","1350 step train acc     : (0.790625, 0.09375, 0.875)\n","1360 step train acc     : (0.771875, 0.109375, 0.84375)\n","1370 step train acc     : (0.6554687499999999, 0.0625, 0.734375)\n","1380 step train acc     : (0.775, 0.0625, 0.875)\n","1390 step train acc     : (0.83046875, 0.09375, 0.921875)\n","1400 step train acc     : (0.79375, 0.046875, 0.90625)\n","1410 step train acc     : (0.8015625, 0.0625, 0.90625)\n","1420 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","1430 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","1440 step train acc     : (0.78515625, 0.109375, 0.859375)\n","1450 step train acc     : (0.74296875, 0.078125, 0.828125)\n","1460 step train acc     : (0.771875, 0.109375, 0.84375)\n","1470 step train acc     : (0.7984375, 0.109375, 0.875)\n","1480 step train acc     : (0.771875, 0.109375, 0.84375)\n","1490 step train acc     : (0.703125, 0.078125, 0.78125)\n","1500 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","1510 step train acc     : (0.8140625, 0.140625, 0.875)\n","1520 step train acc     : (0.78515625, 0.109375, 0.859375)\n","1530 step train acc     : (0.7671875, 0.046875, 0.875)\n","1540 step train acc     : (0.78515625, 0.109375, 0.859375)\n","1550 step train acc     : (0.81796875, 0.015625, 0.953125)\n","1560 step train acc     : (0.7984375, 0.109375, 0.875)\n","1570 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","1580 step train acc     : (0.79296875, 0.125, 0.859375)\n","1590 step train acc     : (0.83828125, 0.109375, 0.921875)\n","1600 step train acc     : (0.740625, 0.046875, 0.84375)\n","1610 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","1620 step train acc     : (0.7484375, 0.0625, 0.84375)\n","1630 step train acc     : (0.76171875, 0.0625, 0.859375)\n","1640 step train acc     : (0.8140625, 0.140625, 0.875)\n","1650 step train acc     : (0.778125, 0.015625, 0.90625)\n","1660 step train acc     : (0.7484375, 0.0625, 0.84375)\n","1670 step train acc     : (0.75390625, 0.046875, 0.859375)\n","1680 step train acc     : (0.76171875, 0.0625, 0.859375)\n","1690 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","1700 step train acc     : (0.85390625, 0.140625, 0.921875)\n","1710 step train acc     : (0.83359375, 0.046875, 0.953125)\n","1720 step train acc     : (0.8171875, 0.09375, 0.90625)\n","1730 step train acc     : (0.80703125, 0.046875, 0.921875)\n","1740 step train acc     : (0.809375, 0.078125, 0.90625)\n","1750 step train acc     : (0.790625, 0.09375, 0.875)\n","1760 step train acc     : (0.83046875, 0.09375, 0.921875)\n","1770 step train acc     : (0.8171875, 0.09375, 0.90625)\n","1780 step train acc     : (0.821875, 0.15625, 0.875)\n","1790 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","1800 step train acc     : (0.85390625, 0.140625, 0.921875)\n","1810 step train acc     : (0.8515625, 0.109375, 0.9375)\n","1820 step train acc     : (0.859375, 0.125, 0.9375)\n","1830 step train acc     : (0.70078125, 0.046875, 0.796875)\n","1840 step train acc     : (0.81484375, 0.0625, 0.921875)\n","1850 step train acc     : (0.7484375, 0.0625, 0.84375)\n","1860 step train acc     : (0.83046875, 0.09375, 0.921875)\n","1870 step train acc     : (0.7671875, 0.046875, 0.875)\n","1880 step train acc     : (0.80703125, 0.046875, 0.921875)\n","1890 step train acc     : (0.81640625, 0.171875, 0.859375)\n","1900 step train acc     : (0.73515625, 0.0625, 0.828125)\n","1910 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","1920 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","1930 step train acc     : (0.8515625, 0.109375, 0.9375)\n","1940 step train acc     : (0.85625, 0.171875, 0.90625)\n","1950 step train acc     : (0.809375, 0.078125, 0.90625)\n","1960 step train acc     : (0.8328125, 0.125, 0.90625)\n","1970 step train acc     : (0.775, 0.0625, 0.875)\n","1980 step train acc     : (0.7265625, 0.125, 0.78125)\n","1990 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2000 step train acc     : (0.8515625, 0.109375, 0.9375)\n","====================================================================================================\n","0 step val acc     : (0.74150390625, 0.0751953125, 0.828125)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","2010 step train acc     : (0.76171875, 0.0625, 0.859375)\n","2020 step train acc     : (0.74609375, 0.03125, 0.859375)\n","2030 step train acc     : (0.7640625, 0.09375, 0.84375)\n","2040 step train acc     : (0.7484375, 0.0625, 0.84375)\n","2050 step train acc     : (0.825, 0.109375, 0.90625)\n","2060 step train acc     : (0.821875, 0.15625, 0.875)\n","2070 step train acc     : (0.82265625, 0.078125, 0.921875)\n","2080 step train acc     : (0.76171875, 0.0625, 0.859375)\n","2090 step train acc     : (0.840625, 0.140625, 0.90625)\n","2100 step train acc     : (0.8359375, 0.078125, 0.9375)\n","2110 step train acc     : (0.8328125, 0.125, 0.90625)\n","2120 step train acc     : (0.8140625, 0.140625, 0.875)\n","2130 step train acc     : (0.7796875, 0.125, 0.84375)\n","2140 step train acc     : (0.7453124999999999, 0.109375, 0.8125)\n","2150 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","2160 step train acc     : (0.77734375, 0.09375, 0.859375)\n","2170 step train acc     : (0.76953125, 0.078125, 0.859375)\n","2180 step train acc     : (0.775, 0.0625, 0.875)\n","2190 step train acc     : (0.8195312499999999, 0.125, 0.890625)\n","2200 step train acc     : (0.75078125, 0.09375, 0.828125)\n","2210 step train acc     : (0.84921875, 0.078125, 0.953125)\n","2220 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","2230 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2240 step train acc     : (0.72734375, 0.046875, 0.828125)\n","2250 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","2260 step train acc     : (0.77421875, 0.140625, 0.828125)\n","2270 step train acc     : (0.7828125, 0.078125, 0.875)\n","2280 step train acc     : (0.7796875, 0.125, 0.84375)\n","2290 step train acc     : (0.778125, 0.015625, 0.90625)\n","2300 step train acc     : (0.790625, 0.09375, 0.875)\n","2310 step train acc     : (0.78515625, 0.109375, 0.859375)\n","2320 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","2330 step train acc     : (0.78515625, 0.109375, 0.859375)\n","2340 step train acc     : (0.8546874999999999, 0.0625, 0.96875)\n","2350 step train acc     : (0.76953125, 0.078125, 0.859375)\n","2360 step train acc     : (0.8781249999999999, 0.109375, 0.96875)\n","2370 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2380 step train acc     : (0.78515625, 0.109375, 0.859375)\n","2390 step train acc     : (0.75625, 0.078125, 0.84375)\n","2400 step train acc     : (0.80625, 0.125, 0.875)\n","2410 step train acc     : (0.7859375, 0.03125, 0.90625)\n","2420 step train acc     : (0.6734375, 0.125, 0.71875)\n","2430 step train acc     : (0.82265625, 0.078125, 0.921875)\n","2440 step train acc     : (0.76953125, 0.078125, 0.859375)\n","2450 step train acc     : (0.76640625, 0.125, 0.828125)\n","2460 step train acc     : (0.81640625, 0.171875, 0.859375)\n","2470 step train acc     : (0.79375, 0.046875, 0.90625)\n","2480 step train acc     : (0.85703125, 0.09375, 0.953125)\n","2490 step train acc     : (0.7828125, 0.078125, 0.875)\n","2500 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","2510 step train acc     : (0.88828125, 0.15625, 0.953125)\n","2520 step train acc     : (0.76171875, 0.0625, 0.859375)\n","2530 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","2540 step train acc     : (0.7531249999999999, 0.125, 0.8125)\n","2550 step train acc     : (0.825, 0.109375, 0.90625)\n","2560 step train acc     : (0.70859375, 0.0625, 0.796875)\n","2570 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2580 step train acc     : (0.775, 0.0625, 0.875)\n","2590 step train acc     : (0.778125, 0.015625, 0.90625)\n","2600 step train acc     : (0.75390625, 0.046875, 0.859375)\n","2610 step train acc     : (0.76953125, 0.078125, 0.859375)\n","2620 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","2630 step train acc     : (0.7484375, 0.0625, 0.84375)\n","2640 step train acc     : (0.83359375, 0.046875, 0.953125)\n","2650 step train acc     : (0.72421875, 0.09375, 0.796875)\n","2660 step train acc     : (0.7828125, 0.078125, 0.875)\n","2670 step train acc     : (0.83828125, 0.109375, 0.921875)\n","2680 step train acc     : (0.73515625, 0.0625, 0.828125)\n","2690 step train acc     : (0.75859375, 0.109375, 0.828125)\n","2700 step train acc     : (0.72734375, 0.046875, 0.828125)\n","2710 step train acc     : (0.8140625, 0.140625, 0.875)\n","2720 step train acc     : (0.79296875, 0.125, 0.859375)\n","2730 step train acc     : (0.73515625, 0.0625, 0.828125)\n","2740 step train acc     : (0.8171875, 0.09375, 0.90625)\n","2750 step train acc     : (0.80703125, 0.046875, 0.921875)\n","2760 step train acc     : (0.83828125, 0.109375, 0.921875)\n","2770 step train acc     : (0.8039062499999999, 0.09375, 0.890625)\n","2780 step train acc     : (0.83046875, 0.09375, 0.921875)\n","2790 step train acc     : (0.83828125, 0.109375, 0.921875)\n","2800 step train acc     : (0.82265625, 0.078125, 0.921875)\n","2810 step train acc     : (0.83046875, 0.09375, 0.921875)\n","2820 step train acc     : (0.82265625, 0.078125, 0.921875)\n","2830 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","2840 step train acc     : (0.71953125, 0.03125, 0.828125)\n","2850 step train acc     : (0.77734375, 0.09375, 0.859375)\n","2860 step train acc     : (0.8171875, 0.09375, 0.90625)\n","2870 step train acc     : (0.84609375, 0.125, 0.921875)\n","2880 step train acc     : (0.7484375, 0.0625, 0.84375)\n","2890 step train acc     : (0.8140625, 0.140625, 0.875)\n","2900 step train acc     : (0.8195312499999999, 0.125, 0.890625)\n","2910 step train acc     : (0.7374999999999999, 0.09375, 0.8125)\n","2920 step train acc     : (0.7484375, 0.0625, 0.84375)\n","2930 step train acc     : (0.80703125, 0.046875, 0.921875)\n","2940 step train acc     : (0.8171875, 0.09375, 0.90625)\n","2950 step train acc     : (0.8195312499999999, 0.125, 0.890625)\n","2960 step train acc     : (0.79375, 0.046875, 0.90625)\n","2970 step train acc     : (0.790625, 0.09375, 0.875)\n","2980 step train acc     : (0.7140624999999999, 0.046875, 0.8125)\n","2990 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","3000 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","====================================================================================================\n","0 step val acc     : (0.750048828125, 0.083984375, 0.8330078125)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","3010 step train acc     : (0.828125, 0.0625, 0.9375)\n","3020 step train acc     : (0.76953125, 0.078125, 0.859375)\n","3030 step train acc     : (0.7671875, 0.046875, 0.875)\n","3040 step train acc     : (0.7640625, 0.09375, 0.84375)\n","3050 step train acc     : (0.82265625, 0.078125, 0.921875)\n","3060 step train acc     : (0.7726562499999999, 0.03125, 0.890625)\n","3070 step train acc     : (0.7671875, 0.046875, 0.875)\n","3080 step train acc     : (0.809375, 0.078125, 0.90625)\n","3090 step train acc     : (0.775, 0.0625, 0.875)\n","3100 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","3110 step train acc     : (0.83046875, 0.09375, 0.921875)\n","3120 step train acc     : (0.8125, 0.03125, 0.9375)\n","3130 step train acc     : (0.75859375, 0.109375, 0.828125)\n","3140 step train acc     : (0.7640625, 0.09375, 0.84375)\n","3150 step train acc     : (0.75078125, 0.09375, 0.828125)\n","3160 step train acc     : (0.8273437499999999, 0.140625, 0.890625)\n","3170 step train acc     : (0.86484375, 0.109375, 0.953125)\n","3180 step train acc     : (0.75078125, 0.09375, 0.828125)\n","3190 step train acc     : (0.8015625, 0.0625, 0.90625)\n","3200 step train acc     : (0.8015625, 0.0625, 0.90625)\n","3210 step train acc     : (0.809375, 0.078125, 0.90625)\n","3220 step train acc     : (0.8359375, 0.078125, 0.9375)\n","3230 step train acc     : (0.85625, 0.171875, 0.90625)\n","3240 step train acc     : (0.7484375, 0.0625, 0.84375)\n","3250 step train acc     : (0.7671875, 0.046875, 0.875)\n","3260 step train acc     : (0.80078125, 0.140625, 0.859375)\n","3270 step train acc     : (0.72734375, 0.046875, 0.828125)\n","3280 step train acc     : (0.77734375, 0.09375, 0.859375)\n","3290 step train acc     : (0.859375, 0.125, 0.9375)\n","3300 step train acc     : (0.75859375, 0.109375, 0.828125)\n","3310 step train acc     : (0.7804687499999999, 0.046875, 0.890625)\n","3320 step train acc     : (0.8375, 0.1875, 0.875)\n","3330 step train acc     : (0.75390625, 0.046875, 0.859375)\n","3340 step train acc     : (0.840625, 0.140625, 0.90625)\n","3350 step train acc     : (0.7882812499999999, 0.0625, 0.890625)\n","3360 step train acc     : (0.740625, 0.046875, 0.84375)\n","3370 step train acc     : (0.8015625, 0.0625, 0.90625)\n","3380 step train acc     : (0.759375, 0.03125, 0.875)\n","3390 step train acc     : (0.83046875, 0.09375, 0.921875)\n","3400 step train acc     : (0.82265625, 0.078125, 0.921875)\n","3410 step train acc     : (0.7828125, 0.078125, 0.875)\n","3420 step train acc     : (0.75625, 0.078125, 0.84375)\n","3430 step train acc     : (0.73828125, 0.015625, 0.859375)\n","3440 step train acc     : (0.84921875, 0.078125, 0.953125)\n","3450 step train acc     : (0.75078125, 0.09375, 0.828125)\n","3460 step train acc     : (0.8015625, 0.0625, 0.90625)\n","3470 step train acc     : (0.71640625, 0.078125, 0.796875)\n","3480 step train acc     : (0.8171875, 0.09375, 0.90625)\n","3490 step train acc     : (0.809375, 0.078125, 0.90625)\n","3500 step train acc     : (0.76953125, 0.078125, 0.859375)\n","3510 step train acc     : (0.84140625, 0.0625, 0.953125)\n","3520 step train acc     : (0.7875, 0.140625, 0.84375)\n","3530 step train acc     : (0.853125, 0.21875, 0.875)\n","3540 step train acc     : (0.7984375, 0.109375, 0.875)\n","3550 step train acc     : (0.7609374999999999, 0.140625, 0.8125)\n","3560 step train acc     : (0.7828125, 0.078125, 0.875)\n","3570 step train acc     : (0.82265625, 0.078125, 0.921875)\n","3580 step train acc     : (0.775, 0.0625, 0.875)\n","3590 step train acc     : (0.775, 0.0625, 0.875)\n","3600 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3610 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3620 step train acc     : (0.7984375, 0.109375, 0.875)\n","3630 step train acc     : (0.62890625, 0.0625, 0.703125)\n","3640 step train acc     : (0.8171875, 0.09375, 0.90625)\n","3650 step train acc     : (0.84921875, 0.078125, 0.953125)\n","3660 step train acc     : (0.78515625, 0.109375, 0.859375)\n","3670 step train acc     : (0.809375, 0.078125, 0.90625)\n","3680 step train acc     : (0.825, 0.109375, 0.90625)\n","3690 step train acc     : (0.76171875, 0.0625, 0.859375)\n","3700 step train acc     : (0.76640625, 0.125, 0.828125)\n","3710 step train acc     : (0.7296874999999999, 0.078125, 0.8125)\n","3720 step train acc     : (0.775, 0.0625, 0.875)\n","3730 step train acc     : (0.7640625, 0.09375, 0.84375)\n","3740 step train acc     : (0.77734375, 0.09375, 0.859375)\n","3750 step train acc     : (0.790625, 0.09375, 0.875)\n","3760 step train acc     : (0.775, 0.0625, 0.875)\n","3770 step train acc     : (0.79375, 0.046875, 0.90625)\n","3780 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3790 step train acc     : (0.79296875, 0.125, 0.859375)\n","3800 step train acc     : (0.79375, 0.046875, 0.90625)\n","3810 step train acc     : (0.75390625, 0.046875, 0.859375)\n","3820 step train acc     : (0.75390625, 0.046875, 0.859375)\n","3830 step train acc     : (0.83828125, 0.109375, 0.921875)\n","3840 step train acc     : (0.78515625, 0.109375, 0.859375)\n","3850 step train acc     : (0.7218749999999999, 0.0625, 0.8125)\n","3860 step train acc     : (0.72421875, 0.09375, 0.796875)\n","3870 step train acc     : (0.75625, 0.078125, 0.84375)\n","3880 step train acc     : (0.73984375, 0.125, 0.796875)\n","3890 step train acc     : (0.7828125, 0.078125, 0.875)\n","3900 step train acc     : (0.8351562499999999, 0.15625, 0.890625)\n","3910 step train acc     : (0.76171875, 0.0625, 0.859375)\n","3920 step train acc     : (0.840625, 0.140625, 0.90625)\n","3930 step train acc     : (0.809375, 0.078125, 0.90625)\n","3940 step train acc     : (0.775, 0.0625, 0.875)\n","3950 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3960 step train acc     : (0.809375, 0.078125, 0.90625)\n","3970 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","3980 step train acc     : (0.74296875, 0.078125, 0.828125)\n","3990 step train acc     : (0.8117187499999999, 0.109375, 0.890625)\n","4000 step train acc     : (0.76171875, 0.0625, 0.859375)\n","====================================================================================================\n","0 step val acc     : (0.735107421875, 0.083984375, 0.8154296875)\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","4010 step train acc     : (0.775, 0.0625, 0.875)\n","4020 step train acc     : (0.8328125, 0.125, 0.90625)\n","4030 step train acc     : (0.80625, 0.125, 0.875)\n","4040 step train acc     : (0.8171875, 0.09375, 0.90625)\n","4050 step train acc     : (0.7328125, 0.03125, 0.84375)\n","4060 step train acc     : (0.71640625, 0.078125, 0.796875)\n","4070 step train acc     : (0.7960937499999999, 0.078125, 0.890625)\n","4080 step train acc     : (0.72734375, 0.046875, 0.828125)\n","4090 step train acc     : (0.6765625, 0.078125, 0.75)\n"]}],"source":["from torch.utils.data import DataLoader\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/colab_data/cj_data/model/Bert_DNN_Classification')\n","import category_model_from_scratch\n","import category_dataset_from_scratch\n","import random\n","import numpy as np\n","\n","# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device = 'cpu'\n","print(device)\n","\n","# Param Set\n","class CFG:\n","  epochs = 5\n","  batch_size = 64\n","  learning_rate=3.0e-4\n","  weight_decay=0.01\n","  warmup_steps = 100\n","  print_freq=10\n","\n","  text_encoder_size = 768\n","  hidden_size = 768\n","  dropout = 0.2\n","  \n","  seed = 7\n","\n","  vocab_size = 32000 # 토큰의 유니크 인덱스 개수\n","  type_vocab_size = 30 # 타입의 유니크 인덱스 개수\n","  seq_len=64 # 토큰의 최대 길이\n","  nlayers = 2\n","  nheads=8 # BERT의 head 개수\n","  intermediate_size=256 # TRANSFORMER셀의 intermediate 크기\n","\n","\n","  main_ctg = data_df.main_ctg.unique().shape[0]\n","  midd_ctg = data_df.midd_ctg.unique().shape[0]\n","\n","# 랜덤 시드를 설정하여 매 코드를 실행할 때마다 동일한 결과를 얻게 합니다.\n","os.environ['PYTHONHASHSEED'] = str(CFG.seed)\n","random.seed(CFG.seed)\n","np.random.seed(CFG.seed)\n","torch.manual_seed(CFG.seed)    \n","torch.cuda.manual_seed(CFG.seed)\n","torch.backends.cudnn.deterministic = True\n","\n","\n","# 토큰을 대응되는 인덱스로 치환할 때 사용될 딕셔너리를 로딩합니다.\n","PROCESSED_DATA_DIR = '/content/drive/MyDrive/colab_data/cj_data/data/bert/' # 전처리된 데이터가 저장될 디렉터리\n","VOCAB_DIR =os.path.join(PROCESSED_DATA_DIR, 'vocab') # 전처리에 사용될 사전 파일이 저장될 디렉터리\n","\n","vocab = [line.split('\\t')[0] for line in open(os.path.join(VOCAB_DIR, 'spm_v2.vocab'), encoding='utf-8').readlines()]\n","token2id = dict([(w, i) for i, w in enumerate(vocab)])\n","print('loading ... done')\n","\n","train_db = category_dataset_from_scratch.CategoryDataSet(train_data, token2id , CFG.seq_len, CFG.type_vocab_size)\n","train_loader = DataLoader(train_db, batch_size = CFG.batch_size)\n","\n","val_db = category_dataset_from_scratch.CategoryDataSet(val_data, token2id , CFG.seq_len, CFG.type_vocab_size)\n","val_loader = DataLoader(val_db, batch_size = 1024)\n","\n","\n","# Model Set\n","# model = category_model.CategoryClassifier(CFG)\n","# model = category_model_from_scratch.CategoryClassifier(CFG)\n","MODEL_PATH = '/content/drive/MyDrive/colab_data/cj_data/saved_model/'\n","# model = model.to(device)\n","\n","num_train_optimization_steps = int(\n","        len(train_db) / CFG.batch_size) * (CFG.epochs)\n","print('num_train_optimization_steps', num_train_optimization_steps)\n","\n","# Optimizer Set\n","param_optimizer = list(model.named_parameters())   \n","no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params':[p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","     'weight_decay': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \n","     'weight_decay': 0.0}\n","]\n","optimizer = AdamW(model.parameters(), lr = 3.0e-4)\n","\n","# Sheduler Set\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps=CFG.warmup_steps,\n","                                            num_training_steps=num_train_optimization_steps)\n","print('use WarmupLinearSchedule ...')\n","print(model)\n","\n","\n","for epoch in range(CFG.epochs):\n","  print(epoch)\n","  train(train_loader,val_loader, model, optimizer, epoch, scheduler)\n","\n","  # 모델의 파라미터를 저장합니다.\n","  save_checkpoint({\n","      'epoch': epoch + 1,\n","      'arch': 'transformer',\n","      'state_dict': model.state_dict(),\n","      'log': log_df,\n","      },\n","      MODEL_PATH, f'model_from_scratch_v2_batch{CFG.batch_size}_epoch{epoch+2}.pt',\n","  )"]},{"cell_type":"markdown","source":["## Test Section"],"metadata":{"id":"dnvnFVHiC0_7"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1722,"status":"ok","timestamp":1644535099630,"user":{"displayName":"최수산","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15495732425338237971"},"user_tz":-540},"id":"RfntpgA11_I6","outputId":"8dce71f9-0f93-41fc-fa71-1bd24ee301c6"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Param Set\n","class CFG:\n","  epochs = 3\n","  batch_size = 256\n","  learning_rate=3.0e-4\n","  weight_decay=0.01\n","  warmup_steps = 100\n","  print_freq=100\n","\n","  text_encoder_size = 768\n","  hidden_size = 768\n","  dropout = 0.2\n","  \n","  seed = 7\n","\n","  vocab_size = 32000 # 토큰의 유니크 인덱스 개수\n","  type_vocab_size = 30 # 타입의 유니크 인덱스 개수\n","  seq_len=64 # 토큰의 최대 길이\n","  nlayers = 2\n","  nheads=8 # BERT의 head 개수\n","  intermediate_size=256 # TRANSFORMER셀의 intermediate 크기\n","\n","  main_ctg = data_df.main_ctg.unique().shape[0]\n","  midd_ctg = data_df.midd_ctg.unique().shape[0]\n","\n","import sys\n","sys.path.append('/content/drive/MyDrive/colab_data/cj_data/model/Bert_DNN_Classification')\n","import category_model_from_scratch\n","import category_dataset_from_scratch\n","\n","model = category_model_from_scratch.CategoryClassifier(CFG)\n","mode_state_dict = torch.load('/content/drive/MyDrive/colab_data/cj_data/saved_model/model_from_scratch_v2_batch64_epoch1.pt')\n","model.load_state_dict(mode_state_dict['state_dict'], strict = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fI5gT71vUAlU"},"outputs":[],"source":["# Test\n","import torch\n","\n","# 토큰을 대응되는 인덱스로 치환할 때 사용될 딕셔너리를 로딩합니다.\n","PROCESSED_DATA_DIR = '/content/drive/MyDrive/colab_data/cj_data/data/bert/' # 전처리된 데이터가 저장될 디렉터리\n","VOCAB_DIR =os.path.join(PROCESSED_DATA_DIR, 'vocab') # 전처리에 사용될 사전 파일이 저장될 디렉터리\n","\n","vocab = [line.split('\\t')[0] for line in open(os.path.join(VOCAB_DIR, 'spm_v2.vocab'), encoding='utf-8').readlines()]\n","token2id = dict([(w, i) for i, w in enumerate(vocab)])\n","print('loading ... done')\n","\n","# Test Data Load\n","test_db = category_dataset_from_scratch.CategoryDataSet(test_data, token2id , CFG.seq_len, CFG.type_vocab_size)\n","test_loader = DataLoader(test_db, batch_size = 1)\n","ctg_dict = data_df[['middle_classification', 'main_ctg', 'midd_ctg']].drop_duplicates()\n","\n","def inference(model, model_name):\n","    score = 0\n","    \n","    incorrect_pred = []\n","    for step, (token_ids, token_mask, token_types, label) in enumerate(test_loader):\n","\n","        # with문 내에서는 그래디언트 계산을 하지 않도록 함\n","        with torch.no_grad():\n","            # model은 배치 데이터를 입력 받아서 예측 결과 및 loss 반환\n","\n","        #     token_ids, token_mask, token_types, label = (\n","        # token_ids.cuda(), token_mask.cuda(), token_types.cuda(), label.cuda())\n","\n","         loss, pred = model(token_ids, token_mask, token_types, label)\n","\n","        main_label, midd_label = label[0]\n","\n","        main_pred, midd_pred = pred\n","        _, main_idx = main_pred.max(1)\n","        _, midd_idx = midd_pred.max(1)\n","\n","        if int(midd_label) != int(midd_idx):\n","            incorrect_pred.append([test_data.iloc[step, :]['name'], ctg_dict[ctg_dict.midd_ctg == int(midd_label)].middle_classification.iloc[0], ctg_dict[ctg_dict.midd_ctg == int(midd_idx)].middle_classification.iloc[0]])\n","            # print(midd_label, midd_idx)\n","            # print('='*100)\n","            # print(test_data.iloc[step, :])\n","            # print(f'label: {ctg_dict[ctg_dict.midd_ctg == int(midd_label)].middle_classification.iloc[0]}')\n","            # print(f'pred : {ctg_dict[ctg_dict.midd_ctg == int(midd_idx)].middle_classification.iloc[0]}')\n","        else:\n","            score += 1\n","\n","        o_acc, main_acc, midd_acc = calc_cate_acc(pred, label)\n","\n","        # print(o_acc, main_acc, midd_acc)\n","    print('='*100)\n","    \n","    print(f'model_name: {model_name} acc score: {score / len(test_loader)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lWrg1s9r6DpL"},"outputs":[],"source":["# epoch 별 성능 평가\n","for i in range(4):\n","    model = category_model_from_scratch.CategoryClassifier(CFG)\n","    mode_state_dict = torch.load(f'/content/drive/MyDrive/colab_data/cj_data/saved_model/model_from_scratch_v2_batch64_epoch{i+1}.pt')\n","    model.load_state_dict(mode_state_dict['state_dict'], strict = True)\n","\n","    inference(model, f'model_from_scratch_v2_batch64_epoch{i+1}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MpJLdLvtxI9"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"nlp_classification_from_scratch.ipynb","provenance":[],"mount_file_id":"1j_u9-UNhwQhUNjCnhXIUgANvZc02-b1u","authorship_tag":"ABX9TyMPEjEvnDy/bN9oXCt9VdL3"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}